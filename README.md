# PyTorch Neural Network: Multi-Layer Perceptron for Regression 

This project implements a flexible multi-layer perceptron (MLP) using PyTorch, built to handle both 1D and 2D inputs and designed for scalar regression tasks. The architecture includes three hidden layers with ReLU activations, and a 1-dimensional output.


## The repository includes a single Jupyter notebook with:
- Custom MLP class using PyTorch
- Support for variable input dimensions
- ReLU-based architecture
- Code explanation via inline comments
- A written comparison of ReLU vs Sigmoid for regression tasks

## Features

- Clean object-oriented MLP implementation (`nn.Module`)
- Three hidden layers (16 neurons each)
- ReLU activations (hidden layers)
- Linear output (for regression)
- Written analysis on activation functions

## Technologies Used

- Python 3.x
- PyTorch
- Jupyter Notebook
